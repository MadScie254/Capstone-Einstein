{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection and Theft Modeling\n",
    "## Non-Technical Loss Detection Pipeline\n",
    "\n",
    "**Document Type:** Technical Analysis Report  \n",
    "**Audience:** Data Scientists, ML Engineers, Model Reviewers  \n",
    "**Prerequisites:** Complete notebooks 01 and 02; all artifacts must be generated  \n",
    "\n",
    "---\n",
    "\n",
    "### Objective\n",
    "\n",
    "Train and calibrate detection models using a hybrid approach:\n",
    "1. **Unsupervised (Isolation Forest):** Anomaly detection per customer cluster\n",
    "2. **Supervised (XGBoost):** Classification using historical labels\n",
    "3. **Ensemble scoring:** Combined probability with confidence weighting\n",
    "\n",
    "### Outputs\n",
    "\n",
    "- `artifacts/model_xgb.joblib` - Trained XGBoost classifier\n",
    "- `artifacts/model_isolation_cluster_*.joblib` - Cluster-specific Isolation Forest models\n",
    "- `artifacts/thresholds.json` - Calibrated detection thresholds\n",
    "- `artifacts/metadata.json` - Model metadata and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import (\n",
    "    classification_report, precision_recall_curve, auc,\n",
    "    confusion_matrix, roc_auc_score\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / 'artifacts'\n",
    "\n",
    "print(f'Project Root: {PROJECT_ROOT}')\n",
    "print(f'Execution Time: {datetime.now().isoformat()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features with cluster assignments\n",
    "features = pd.read_parquet(ARTIFACTS_DIR / 'preprocessed.parquet')\n",
    "\n",
    "print('=== DATA LOADED ===')\n",
    "print(f'Records: {len(features):,}')\n",
    "print(f'Features: {len(features.columns)}')\n",
    "\n",
    "# Identify feature columns\n",
    "exclude_cols = ['CONS_NO', 'FLAG', 'quality_flag', 'cluster']\n",
    "feature_cols = [c for c in features.columns if c not in exclude_cols]\n",
    "\n",
    "print(f'Model features: {len(feature_cols)}')\n",
    "\n",
    "# Check for labels\n",
    "has_labels = 'FLAG' in features.columns and features['FLAG'].nunique() > 1\n",
    "print(f'Labeled data available: {has_labels}')\n",
    "\n",
    "if has_labels:\n",
    "    print(f'Label distribution: {features[\"FLAG\"].value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare modeling data\n",
    "# Filter to high-quality records\n",
    "if 'quality_flag' in features.columns:\n",
    "    model_data = features[features['quality_flag'] == 'HIGH'].copy()\n",
    "else:\n",
    "    model_data = features.copy()\n",
    "\n",
    "X = model_data[feature_cols].values.astype(np.float32)\n",
    "X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "if has_labels:\n",
    "    y = model_data['FLAG'].values\n",
    "\n",
    "print(f'\\nModeling data shape: {X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split\n",
    "\n",
    "Stratified split to preserve class balance across partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_labels:\n",
    "    # Stratified split: 60% train, 20% validation, 20% test\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42\n",
    "    )\n",
    "    \n",
    "    print('=== DATA SPLIT ===')\n",
    "    print(f'Training:   {len(X_train):,} samples (theft rate: {y_train.mean():.2%})')\n",
    "    print(f'Validation: {len(X_val):,} samples (theft rate: {y_val.mean():.2%})')\n",
    "    print(f'Test:       {len(X_test):,} samples (theft rate: {y_test.mean():.2%})')\n",
    "else:\n",
    "    X_train = X\n",
    "    print('No labels available. Unsupervised methods only.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unsupervised Detection: Isolation Forest\n",
    "\n",
    "### Rationale\n",
    "\n",
    "Isolation Forest is effective for anomaly detection because:\n",
    "- Does not require labeled data\n",
    "- Handles high-dimensional feature spaces\n",
    "- Computationally efficient for large datasets\n",
    "\n",
    "We train cluster-specific models to account for behavioral heterogeneity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Isolation Forest models per cluster\n",
    "iso_models = {}\n",
    "\n",
    "if 'cluster' in model_data.columns:\n",
    "    clusters = model_data['cluster'].unique()\n",
    "    clusters = [c for c in clusters if c >= 0]  # Exclude unassigned (-1)\n",
    "else:\n",
    "    clusters = [0]  # Single global model\n",
    "\n",
    "print('=== ISOLATION FOREST TRAINING ===')\n",
    "\n",
    "for cluster_id in clusters:\n",
    "    if 'cluster' in model_data.columns:\n",
    "        cluster_mask = model_data['cluster'] == cluster_id\n",
    "        X_cluster = X[cluster_mask]\n",
    "    else:\n",
    "        X_cluster = X\n",
    "    \n",
    "    # Set contamination based on expected theft rate\n",
    "    contamination = 0.1  # Conservative estimate\n",
    "    \n",
    "    iso_model = IsolationForest(\n",
    "        n_estimators=100,\n",
    "        contamination=contamination,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    iso_model.fit(X_cluster)\n",
    "    iso_models[cluster_id] = iso_model\n",
    "    \n",
    "    print(f'Cluster {cluster_id}: trained on {len(X_cluster):,} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Isolation Forest (if labels available)\n",
    "if has_labels:\n",
    "    # Get anomaly scores for test set\n",
    "    if 'cluster' in model_data.columns:\n",
    "        test_clusters = model_data.iloc[len(X_train)+len(X_val):]['cluster'].values\n",
    "    else:\n",
    "        test_clusters = np.zeros(len(X_test))\n",
    "    \n",
    "    iso_scores = np.zeros(len(X_test))\n",
    "    for i, (x, cluster_id) in enumerate(zip(X_test, test_clusters)):\n",
    "        if cluster_id >= 0 and cluster_id in iso_models:\n",
    "            iso_scores[i] = -iso_models[cluster_id].decision_function([x])[0]\n",
    "        else:\n",
    "            iso_scores[i] = 0\n",
    "    \n",
    "    # Convert to binary predictions using percentile threshold\n",
    "    threshold = np.percentile(iso_scores, 90)\n",
    "    iso_pred = (iso_scores > threshold).astype(int)\n",
    "    \n",
    "    print('\\n=== ISOLATION FOREST EVALUATION ===')\n",
    "    print(classification_report(y_test, iso_pred, target_names=['Normal', 'Theft']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Supervised Detection: XGBoost\n",
    "\n",
    "### Rationale\n",
    "\n",
    "XGBoost is selected for supervised learning because:\n",
    "- Handles class imbalance via scale_pos_weight\n",
    "- Provides feature importance for interpretability\n",
    "- Robust to noisy features\n",
    "- Fast inference for production deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_labels:\n",
    "    # Calculate class weight\n",
    "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    \n",
    "    print('=== XGBOOST TRAINING ===')\n",
    "    print(f'Scale positive weight: {scale_pos_weight:.2f}')\n",
    "    \n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        eval_metric='aucpr',\n",
    "        early_stopping_rounds=20,\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    print(f'Best iteration: {xgb_model.best_iteration}')\n",
    "else:\n",
    "    xgb_model = None\n",
    "    print('Skipping XGBoost training: no labels available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate XGBoost\n",
    "if xgb_model is not None:\n",
    "    xgb_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    xgb_pred = (xgb_proba >= 0.5).astype(int)\n",
    "    \n",
    "    print('\\n=== XGBOOST EVALUATION ===')\n",
    "    print(classification_report(y_test, xgb_pred, target_names=['Normal', 'Theft']))\n",
    "    \n",
    "    # Calculate AUPRC\n",
    "    precision, recall, _ = precision_recall_curve(y_test, xgb_proba)\n",
    "    auprc = auc(recall, precision)\n",
    "    roc_auc = roc_auc_score(y_test, xgb_proba)\n",
    "    \n",
    "    print(f'\\nAUPRC: {auprc:.4f}')\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "if xgb_model is not None:\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': xgb_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print('\\n=== TOP 15 FEATURES BY IMPORTANCE ===')\n",
    "    for i, (_, row) in enumerate(importance.head(15).iterrows(), 1):\n",
    "        print(f'{i:2d}. {row[\"feature\"]}: {row[\"importance\"]:.4f}')\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features = importance.head(15)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'].values[::-1], color='#2E86AB')\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'].values[::-1])\n",
    "    plt.xlabel('Feature Importance (Gain)')\n",
    "    plt.title('XGBoost Feature Importance - Top 15')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ARTIFACTS_DIR / 'feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\nFigure saved: feature_importance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Threshold Calibration\n",
    "\n",
    "### Objective\n",
    "\n",
    "Calibrate thresholds to achieve target precision at operational capacity constraints.\n",
    "\n",
    "For example, if investigation capacity allows reviewing top 2% of flagged customers:\n",
    "- Target: Precision@2% > 60%\n",
    "- Constraint: Monthly flags < 3,000 customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_model is not None:\n",
    "    # Calculate precision at various thresholds\n",
    "    thresholds_to_test = [0.01, 0.02, 0.05, 0.10, 0.20]\n",
    "    \n",
    "    print('=== PRECISION@K ANALYSIS ===')\n",
    "    print(f'{\"k\":>6} {\"Precision\":>12} {\"Flagged\":>12} {\"True Positives\":>15}')\n",
    "    print('-' * 47)\n",
    "    \n",
    "    for k in thresholds_to_test:\n",
    "        n_top = max(1, int(len(y_test) * k))\n",
    "        top_indices = np.argsort(xgb_proba)[-n_top:]\n",
    "        precision_at_k = y_test[top_indices].mean()\n",
    "        true_positives = y_test[top_indices].sum()\n",
    "        \n",
    "        print(f'{k:>6.0%} {precision_at_k:>12.2%} {n_top:>12,} {true_positives:>15,}')\n",
    "    \n",
    "    # Determine operational threshold\n",
    "    # Target: precision > 50% at manageable flag volume\n",
    "    operational_threshold = np.percentile(xgb_proba, 95)  # Top 5%\n",
    "    print(f'\\nOperational threshold (95th percentile): {operational_threshold:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save XGBoost model\n",
    "if xgb_model is not None:\n",
    "    joblib.dump(xgb_model, ARTIFACTS_DIR / 'model_xgb.joblib')\n",
    "    print(f'Saved: {ARTIFACTS_DIR / \"model_xgb.joblib\"}')\n",
    "\n",
    "# Save Isolation Forest models\n",
    "for cluster_id, iso_model in iso_models.items():\n",
    "    path = ARTIFACTS_DIR / f'model_isolation_cluster_{cluster_id}.joblib'\n",
    "    joblib.dump(iso_model, path)\n",
    "    print(f'Saved: {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save thresholds\n",
    "thresholds = {\n",
    "    'xgb_default': 0.5,\n",
    "    'xgb_operational': float(operational_threshold) if xgb_model else 0.5,\n",
    "    'isolation_percentile': 90,\n",
    "    'high_risk': 0.8,\n",
    "    'medium_risk': 0.5\n",
    "}\n",
    "\n",
    "with open(ARTIFACTS_DIR / 'thresholds.json', 'w') as f:\n",
    "    json.dump(thresholds, f, indent=2)\n",
    "print(f'Saved: {ARTIFACTS_DIR / \"thresholds.json\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model metadata\n",
    "metadata = {\n",
    "    'version': '1.0.0',\n",
    "    'created_at': datetime.now().isoformat(),\n",
    "    'pipeline_version': '1.0.0',\n",
    "    'models': {\n",
    "        'xgb': {\n",
    "            'type': 'XGBClassifier',\n",
    "            'n_estimators': 200,\n",
    "            'max_depth': 6,\n",
    "            'auprc': float(auprc) if xgb_model else None\n",
    "        },\n",
    "        'isolation_forest': {\n",
    "            'type': 'IsolationForest',\n",
    "            'n_clusters': len(iso_models),\n",
    "            'contamination': 0.1\n",
    "        }\n",
    "    },\n",
    "    'training': {\n",
    "        'n_samples': len(X_train) if has_labels else len(X),\n",
    "        'n_features': len(feature_cols),\n",
    "        'theft_rate': float(y_train.mean()) if has_labels else None\n",
    "    },\n",
    "    'feature_names': feature_cols\n",
    "}\n",
    "\n",
    "with open(ARTIFACTS_DIR / 'metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f'Saved: {ARTIFACTS_DIR / \"metadata.json\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print('\\n' + '='*60)\n",
    "print('MODEL TRAINING SUMMARY')\n",
    "print('='*60)\n",
    "print(f'\\nModels Trained:')\n",
    "print(f'  - XGBoost Classifier: {\"Yes\" if xgb_model else \"No (no labels)\"}')\n",
    "print(f'  - Isolation Forest: {len(iso_models)} cluster-specific models')\n",
    "print(f'\\nPerformance (Test Set):')\n",
    "if xgb_model:\n",
    "    print(f'  - AUPRC: {auprc:.4f}')\n",
    "    print(f'  - ROC-AUC: {roc_auc:.4f}')\n",
    "print(f'\\nArtifacts:')\n",
    "print(f'  - model_xgb.joblib')\n",
    "for cluster_id in iso_models.keys():\n",
    "    print(f'  - model_isolation_cluster_{cluster_id}.joblib')\n",
    "print(f'  - thresholds.json')\n",
    "print(f'  - metadata.json')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Next Step:** Proceed to 04_Evaluation_and_Risk_Analysis.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
