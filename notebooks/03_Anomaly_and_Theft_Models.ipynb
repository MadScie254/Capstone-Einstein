
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Anomaly Detection & Theft Modeling (Champion-Challenger)\n",
    "\n",
    "## Overview\n",
    "In this notebook, we implement a **Champion-Challenger** framework to select the best electricity theft detection model. We train multiple models (Champion: XGBoost, Challenger: Random Forest) and automatically select the one with the highest AUPRC (Area Under Precision-Recall Curve).\n",
    "\n",
    "We also train an Unsupervised Isolation Forest as a safety net for detecting novel anomaly patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, roc_curve, auc, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "\n",
    "# Set Style\n",
    "plt.style.use('dark_background')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "PROJECT_ROOT = Path('..')\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / 'artifacts'\n",
    "ARTIFACTS_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data\n",
    "Loading the feature-engineered dataset from the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv(ARTIFACTS_DIR / 'preprocessed.csv')\n",
    "print(f\"Data Shape: {df_features.shape}\")\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Champion-Challenger Training\n",
    "We split the data temporally (training on past, validating on future) to prevent leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "X = df_features.drop(columns=['CONS_NO', 'FLAG'])\n",
    "y = df_features['FLAG']\n",
    "\n",
    "# Temporal Split (First 80% Train, Last 20% Valid)\n",
    "train_size = int(len(df_features) * 0.8)\n",
    "X_train, X_val = X.iloc[:train_size], X.iloc[train_size:]\n",
    "y_train, y_val = y.iloc[:train_size], y.iloc[train_size:]\n",
    "\n",
    "print(f\"Train Samples: {len(X_train)}, Validation Samples: {len(X_val)}\")\n",
    "print(f\"Theft Rate Train: {y_train.mean():.2%}, Val: {y_val.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Champion: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=6, \n",
    "    learning_rate=0.1, \n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = model_xgb.predict_proba(X_val)[:, 1]\n",
    "auprc_xgb = average_precision_score(y_val, y_pred_xgb)\n",
    "print(f\"Champion (XGBoost) AUPRC: {auprc_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Challenger: Random Forest (Surgical Ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = model_rf.predict_proba(X_val)[:, 1]\n",
    "auprc_rf = average_precision_score(y_val, y_pred_rf)\n",
    "print(f\"Challenger (Random Forest) AUPRC: {auprc_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Arena: The Conclusion\n",
    "Comparing performance to select the winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Data for both models\n",
    "precision_xgb, recall_xgb, _ = precision_recall_curve(y_val, y_pred_xgb)\n",
    "precision_rf, recall_rf, _ = precision_recall_curve(y_val, y_pred_rf)\n",
    "\n",
    "plt.plot(recall_xgb, precision_xgb, label=f'XGBoost (AUC={auprc_xgb:.3f})', color='cyan')\n",
    "plt.plot(recall_rf, precision_rf, label=f'Random Forest (AUC={auprc_rf:.3f})', color='magenta')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('The Model Arena: Precision-Recall Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if auprc_rf > auprc_xgb:\n",
    "    print(\"üèÜ NEW CHAMPION: Random Forest Wins!\")\n",
    "    best_model = model_rf\n",
    "else:\n",
    "    print(\"üèÜ CHAMPION RETAINED: XGBoost Wins!\")\n",
    "    best_model = model_xgb\n",
    "\n",
    "# Save the winner\n",
    "joblib.dump(best_model, ARTIFACTS_DIR / 'model_xgb.joblib') # Saving to main model path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
